{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot 编码\n",
    "\n",
    "one-hot 编码用来把一个类别标签转化为概率分布\n",
    "\n",
    "如果是共有 5 个类别的话\n",
    "\n",
    "例如标签 标签 tensor([1])\n",
    "\n",
    "```python\n",
    "转化为 tensor([\n",
    "    [0, 1, 0, 0, 0]\n",
    "])  # 第 1 号类别的概率为 1，其余为 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 1324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vec = torch.arange(3)\n",
    "F.one_hot(vec, num_classes=5)  # 类别的个数为 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 7])\n",
      "torch.Size([3, 2, 7])\n"
     ]
    }
   ],
   "source": [
    "mat = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "\n",
    "# batch_size, num_steps,  num_classes\n",
    "mat1 = F.one_hot(mat, 7)\n",
    "print(mat1.shape)\n",
    "\n",
    "# num_steps, batch_size, num_classes\n",
    "# 每次拿到所有样本的同一个时间步上的数据集\n",
    "mat2 = F.one_hot(mat.T, 7)\n",
    "print(mat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 3])"
      ]
     },
     "execution_count": 1326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot 编码逆向转换\n",
    "\n",
    "torch.argmax(torch.tensor([\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 1],\n",
    "]), dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建虚拟数据序列\n",
    "\n",
    "虚拟的数据集的词元是数值 0-19\n",
    "长度为 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "seq = []\n",
    "\n",
    "for i in range(100):\n",
    "    # 每次生成长度为 10 的连续序列\n",
    "    start = randint(0, 10)  # [0, 10] 闭区间随机一个数值\n",
    "    for j in range(start, start+10):\n",
    "        seq.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 0, 19)"
      ]
     },
     "execution_count": 1328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq), min(seq), max(seq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = len(seq)  # 序列数据 seq 的长度\n",
    "num_steps = 20  # 时间步长\n",
    "num_classes = 20  # 有多少个种类的词元;用于生成 ont-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.int64\n",
    "\n",
    "x = torch.tensor(seq, dtype=dtype)\n",
    "X = torch.zeros((T-num_steps, num_steps), dtype=dtype)\n",
    "Y = torch.zeros((T-num_steps, num_steps), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_steps):\n",
    "    X[:, i] = x[i:T-num_steps+i]\n",
    "    Y[:, i] = x[i+1:T-num_steps+i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15,  6])"
      ]
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  8,  9, 10, 11, 12, 13, 14, 15,  6,  7])"
      ]
     },
     "execution_count": 1333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0, :11]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建数据迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50  # 批量大小\n",
    "\n",
    "sample_epochs = X.shape[0] // batch_size\n",
    "num_samples = sample_epochs * batch_size\n",
    "\n",
    "from torch.utils import data\n",
    "dataset = data.TensorDataset(X[:num_samples, :], Y[:num_samples, :])\n",
    "diter =data.DataLoader(dataset=dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n",
      "torch.Size([50, 20])  and  torch.Size([50, 20])\n"
     ]
    }
   ],
   "source": [
    "for _X, _Y in diter:\n",
    "    print(_X.shape, ' and ', _Y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 浅尝 RNN 层的前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 256  # rnn 隐藏层的输出个数 - 也是隐藏单元个数\n",
    "num_classes = 20  # rnn 隐藏层的输入个数 - 也是 ont-hot 编码的长度 - 代表词元种类个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入为 num_classes\n",
    "# 输出为 num_hiddens\n",
    "# 1 层 rnn 堆叠\n",
    "rnn_layer = nn.RNN(num_classes, num_hiddens, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建隐状态\n",
    "\n",
    "每一个样本的前向传播过程都会产生一个隐状态，因此 $H$ 要有 batch_size 行，每一行都是前向传播过程中产生的一个隐状态, 而每个隐状态其实只是中间层的输出，所以有 num_hiddens 列\n",
    "\n",
    "通过 rnn 层输出的是 new_H 也就是 new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 1339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size = (隐藏层个数，批量大小，神经元数量)\n",
    "# 在下方的测试中仅含有 1 个数据样本\n",
    "state = torch.zeros(size=(1, 1, num_hiddens))\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 20])"
      ]
     },
     "execution_count": 1340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (num_steps, batch_size, num_classes)\n",
    "\n",
    "# 创建一个 x_t 样本用于测试 rnn_layer 层的前向传播\n",
    "# 样本数量为 1 序列长度为 3\n",
    "x_t = F.one_hot(torch.tensor([\n",
    "    [1],\n",
    "    [3],\n",
    "    [4]\n",
    "]), 20).float()\n",
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 256]), torch.Size([1, 1, 256]))"
      ]
     },
     "execution_count": 1341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred 是每一个输入的 词元 对应的输出值 形状与 x_t 相同\n",
    "# new_state 是输出的新的隐状态，并且是最后一个时间步输入\n",
    "# 后的最终的包含了所有输入过的序列信息的隐藏状态\n",
    "pred, new_state = rnn_layer(x_t, state)\n",
    "pred.shape, new_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0046,  0.0575, -0.0757], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 1342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[2][0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0046,  0.0575, -0.0757], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 1343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[0][0][:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵的展开逻辑\n",
    "\n",
    "从内层的维度向外层逐层展开\n",
    "\n",
    "时间步数，批量大小，one-hot长度\n",
    "\n",
    "第 0 步中的 第 0 号样本 的 one-hot 编码\n",
    "\n",
    "第 0 步中的 第 1 号样本 的 one-hot 编码\n",
    "\n",
    "...\n",
    "\n",
    "以时间步作为分组排列在二维矩阵上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 时间步数，批量大小\n",
    "data = torch.tensor([\n",
    "    [1, 4],\n",
    "    [2, 5],\n",
    "    [3, 6]\n",
    "])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0]],\n",
       "\n",
       "        [[0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1]]])"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = F.one_hot(data, 7)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 1346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reshape(-1, data.shape[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建 RNN 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # one-hot 编码长度 就是 20\n",
    "        # 隐藏单元个数\n",
    "        # 几层 rnn 堆叠\n",
    "        self.rnn = nn.RNN(20, 256, 1)\n",
    "\n",
    "        # 使用线性层将其转化为概率分布输出\n",
    "        self.linear = nn.Linear(256, 20)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        # 先对输入的小批量样本矩阵做 ont-hot 编码\n",
    "        X = F.one_hot(inputs.T.long(), 20)\n",
    "        X = X.to(torch.float32)\n",
    "        \n",
    "        Y, state = self.rnn(X, state)\n",
    "        output = self.linear(Y.reshape(-1, Y.shape[-1]))\n",
    "        output = self.softmax(output)\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, batch_size):\n",
    "        # rnn 网络堆叠层数，批量大小，隐藏单元个数\n",
    "        return torch.zeros(size=(1, batch_size, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1793, grad_fn=<MeanBackward0>)\n",
      "tensor(2.1694, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a5407310>]"
      ]
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = RNNModel()\n",
    "state = net.begin_state(50)\n",
    "\n",
    "# 使用交叉熵损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 使用 SGD 作为优化器\n",
    "updater = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "all_loss = []\n",
    "nums = 50\n",
    "\n",
    "# 对所有的数据迭代 100 次\n",
    "for i in range(100):\n",
    "    for _X, _Y in diter:\n",
    "        \n",
    "        # 把 Y 进行转置后拉成一个向量\n",
    "        # 这和 forward 函数产生的输出非常像\n",
    "        # 如果再把 y 进行 one-hot 编码后\n",
    "        # 就和 forward 函数中 output 的排布是一样的了\n",
    "        y = _Y.T.reshape(-1)\n",
    "        \n",
    "        # 每开始议论新的小批量数据训练的时候让 state 置零\n",
    "        # 因为当前这一批小批量数据和上一批数据是没关系的\n",
    "        state = net.begin_state(batch_size=batch_size)\n",
    "\t\t\n",
    "        # 产生预测 y_hat 和 新的 state\n",
    "        y_hat, state = net(_X, state)\n",
    "        \n",
    "        # 这里的 loss 传入的 y_hat 是概率分布\n",
    "        # loss 会自动对传入的 y.long() 进行 one-hot 编码\n",
    "        # 然后对 y_hat 和 y.long() 计算交叉熵损失\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "        all_loss.append(l)\n",
    "\n",
    "    nums -= 1\n",
    "    if nums <= 0:\n",
    "        print(all_loss[-1])\n",
    "        nums = 50\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "xs = np.arange(len(all_loss))\n",
    "plt.plot(xs, all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prefix, num_preds, net, device):  #@save\n",
    "    \"\"\"\n",
    "    在prefix后面生成新字符\n",
    "    num_preds: 后续要生成多少个值\n",
    "    net: 你的模型\n",
    "    device: 你要用 cpu 还是 gpu 计算\n",
    "    \"\"\"\n",
    "    # batch_size = 1 ==> 对一个字符串做预测\n",
    "    state = net.begin_state(batch_size=1)\n",
    "    outputs = [int(prefix[0])]  # 把 prefix[0] 的数值类型放进 outputs 中\n",
    "    \n",
    "    # get_input 函数，每次从 outputs 末尾拿一个值\n",
    "    # 然后构造成可以输入到 net 模型中的形状并返回\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    \n",
    "    for y in prefix[1:]:  \n",
    "        # 预热期 ==> 把 prefix 中的信息初始化到 state 中\n",
    "        # y 是从 prefix 的 第1号 元素开始取值的\n",
    "        # 当 y 取 prefix[1] 的时候，此时 get_input() 得到的输入是 prefix[0] \n",
    "        # 刚好是错开的，是没有问题的\n",
    "        # 之所以 state 也是网络的输入参数\n",
    "        # 就是要使用 state 保存 prefix 的信息\n",
    "        # 这样就相当于让网络把 prefix 中的前缀信息都记住了\n",
    "        # 然后后期再预测的时候就是基于 prefix 这一串前缀的基础上进行预测的\n",
    "        # 而不是 prefix[-1] 这单个字符进行预测\n",
    "        inputs = get_input()\n",
    "        _, state = net(inputs, state)\n",
    "        outputs.append(int(y))\n",
    "\n",
    "    # 从这儿开始是预测 prefix 后边的字符\n",
    "    # 每次都用上一次输出的值作为下一次输入的值\n",
    "    # 上一次的输出值是一个时间步上的值，而不是一个序列\n",
    "    # 但是并不用担心，之前所输入到网络中的新信息\n",
    "    # 都被存储在了 state 中\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        # index = int(y.argmax(dim=1))\n",
    "        # outputs.append(y[0][index])\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "\n",
    "    # 把 index 的值 转化成其 对应的 词（这里是字符）\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 1355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('66', 5, net, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0156, 0.8533, 0.1155, 0.0156],\n",
       "        [0.8533, 0.1155, 0.0156, 0.0156]])"
      ]
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([\n",
    "    [1, 5, 3, 1],\n",
    "    [5, 3, 1, 1]\n",
    "]).float()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "softmax(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86bb26bcf3701c754d5fd40db657c5b7e15a074c1099b32f8fc32052c18ad091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
